{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sellers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ Our goal is to find sellers who have repeatedly been underperforming vs. others, and understand why.  \n",
    "This will help us shape our recommendations about how to improve Olist's profit margin for the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è Long Notebook. Once you've read a section, you can collapse it.\n",
    "<details>\n",
    "    <summary> <i>[remainder] Notebook best practices</i></summary>\n",
    "\n",
    "- Code your logic so that your Notebook can always be run from top to bottom without crashing (`Cell --> Run All`)\n",
    "- Name your variables carefully \n",
    "- Use dummy names such as `tmp` for intermediary steps when you know you won't need them later\n",
    "- Clear your code and merge cells when relevant to minimize Notebook size (`Shift-M`)\n",
    "- Hide your cell output if you don't need to see it anymore (double click on the red `Out[]:` section to the left of your cell).\n",
    "- Make heavy use of jupyter nbextention `Collapsable Headings` and `Table of Content` (call a TA if you can't find them)\n",
    "- Use the following shortcuts \n",
    "    - `a` to insert a cell above\n",
    "    - `b` to insert a cell below\n",
    "    - `dd` to delete a cell\n",
    "    - `esc` and `arrows` to move between cells\n",
    "    - `Shift-Enter` to execute cell and move focus to the next one\n",
    "    - use `Shift + Tab` when you're between method brackets e.g. `groupby()` to get the docs! Repeat a few times to open it permanently\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 - `olist/seller.py`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a process similar to `order.py`, we have coded for you the module `olist/seller.py` containing a class `Seller` with a method `Seller().get_training_data` that will return a DataFrame with the following features:\n",
    "  \n",
    "| feature_name \t| type \t| description \t|\n",
    "|:---\t|:---:\t|:---\t|\n",
    "| `seller_id` \t| str \t| the id of the seller **UNIQUE** \t|\n",
    "| `seller_city` \t| str \t| the city where seller is located \t|\n",
    "| `seller_state` \t| str \t| the state where seller is located \t|\n",
    "| `delay_to_carrier` \t| float \t| returns 0 if the order is delivered before the shipping_limit_date, otherwise the value of the delay \t|\n",
    "| `wait_time` \t| float \t| average wait_time (duration of deliveries) per seller \t|\n",
    "| `date_first_sale` \t| datetime \t| date of the first sale on Olist \t|\n",
    "| `date_last_sale` \t| datetime \t| date of the last sale on Olist \t|\n",
    "| `months_on_olist` \t| float \t| round number of months  on Olist\t|\n",
    "| `share_of_five_stars` \t| float \t| share of five-star reviews for orders in which the seller was involved \t|\n",
    "| `share_of_one_stars` \t| float \t| share of one-star reviews for orders in which the seller was involved \t|\n",
    "| `review_score` \t| float \t| average review score for orders in which the seller was involved \t|\n",
    "| `n_orders` \t| int \t| number of unique orders the seller was involved with \t|\n",
    "| `quantity` \t| int \t| total number of items sold by this seller \t|\n",
    "| `quantity_per_order` \t| float \t| average number of items per order for this seller \t|\n",
    "| `sales` \t| float \t| total sales associated with this seller (excluding freight value) in BRL \t|  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Import your new class below and check out your training dataframe !** Take time to look at the code and understand exactly what has been computed for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from olist.data import Olist\n",
    "from olist.order import Order\n",
    "\n",
    "\n",
    "class Seller:\n",
    "    def __init__(self):\n",
    "        # Import data only once\n",
    "        olist = Olist()\n",
    "        self.data = olist.get_data()\n",
    "        self.order = Order()\n",
    "\n",
    "    def get_seller_features(self):\n",
    "        \"\"\"\n",
    "        Returns a DataFrame with:\n",
    "        'seller_id', 'seller_city', 'seller_state'\n",
    "        \"\"\"\n",
    "        sellers = self.data['sellers'].copy(\n",
    "        )  # Make a copy before using inplace=True so as to avoid modifying self.data\n",
    "        sellers.drop('seller_zip_code_prefix', axis=1, inplace=True)\n",
    "        sellers.drop_duplicates(\n",
    "            inplace=True)  # There can be multiple rows per seller\n",
    "        return sellers\n",
    "\n",
    "    def get_seller_delay_wait_time(self):\n",
    "        \"\"\"\n",
    "        Returns a DataFrame with:\n",
    "        'seller_id', 'delay_to_carrier', 'wait_time'\n",
    "        \"\"\"\n",
    "        # Get data\n",
    "        order_items = self.data['order_items'].copy()\n",
    "        orders = self.data['orders'].query(\"order_status=='delivered'\").copy()\n",
    "\n",
    "        ship = order_items.merge(orders, on='order_id')\n",
    "\n",
    "        # Handle datetime\n",
    "        ship.loc[:, 'shipping_limit_date'] = pd.to_datetime(\n",
    "            ship['shipping_limit_date'])\n",
    "        ship.loc[:, 'order_delivered_carrier_date'] = pd.to_datetime(\n",
    "            ship['order_delivered_carrier_date'])\n",
    "        ship.loc[:, 'order_delivered_customer_date'] = pd.to_datetime(\n",
    "            ship['order_delivered_customer_date'])\n",
    "        ship.loc[:, 'order_purchase_timestamp'] = pd.to_datetime(\n",
    "            ship['order_purchase_timestamp'])\n",
    "\n",
    "        # Compute delay and wait_time\n",
    "        def delay_to_logistic_partner(d):\n",
    "            days = np.mean(\n",
    "                (d.order_delivered_carrier_date - d.shipping_limit_date) /\n",
    "                np.timedelta64(24, 'h'))\n",
    "            if days > 0:\n",
    "                return days\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        def order_wait_time(d):\n",
    "            days = np.mean(\n",
    "                (d.order_delivered_customer_date - d.order_purchase_timestamp)\n",
    "                / np.timedelta64(24, 'h'))\n",
    "            return days\n",
    "\n",
    "        delay = ship.groupby('seller_id')\\\n",
    "                    .apply(delay_to_logistic_partner)\\\n",
    "                    .reset_index()\n",
    "        delay.columns = ['seller_id', 'delay_to_carrier']\n",
    "\n",
    "        wait = ship.groupby('seller_id')\\\n",
    "                   .apply(order_wait_time)\\\n",
    "                   .reset_index()\n",
    "        wait.columns = ['seller_id', 'wait_time']\n",
    "\n",
    "        df = delay.merge(wait, on='seller_id')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_active_dates(self):\n",
    "        \"\"\"\n",
    "        Returns a DataFrame with:\n",
    "        'seller_id', 'date_first_sale', 'date_last_sale', 'months_on_olist'\n",
    "        \"\"\"\n",
    "        # First, get only orders that are approved\n",
    "        orders_approved = self.data['orders'][[\n",
    "            'order_id', 'order_approved_at'\n",
    "        ]].dropna()\n",
    "\n",
    "        # Then, create a (orders <> sellers) join table because a seller can appear multiple times in the same order\n",
    "        orders_sellers = orders_approved.merge(self.data['order_items'],\n",
    "                                               on='order_id')[[\n",
    "                                                   'order_id', 'seller_id',\n",
    "                                                   'order_approved_at'\n",
    "                                               ]].drop_duplicates()\n",
    "        orders_sellers[\"order_approved_at\"] = pd.to_datetime(\n",
    "            orders_sellers[\"order_approved_at\"])\n",
    "\n",
    "        # Compute dates\n",
    "        orders_sellers[\"date_first_sale\"] = orders_sellers[\"order_approved_at\"]\n",
    "        orders_sellers[\"date_last_sale\"] = orders_sellers[\"order_approved_at\"]\n",
    "        df = orders_sellers.groupby('seller_id').agg({\n",
    "            \"date_first_sale\": min,\n",
    "            \"date_last_sale\": max\n",
    "        })\n",
    "        df['months_on_olist'] = round(\n",
    "            (df['date_last_sale'] - df['date_first_sale']) /\n",
    "            np.timedelta64(1, 'M'))\n",
    "        return df\n",
    "\n",
    "    def get_quantity(self):\n",
    "        \"\"\"\n",
    "        Returns a DataFrame with:\n",
    "        'seller_id', 'n_orders', 'quantity', 'quantity_per_order'\n",
    "        \"\"\"\n",
    "        order_items = self.data['order_items']\n",
    "\n",
    "        n_orders = order_items.groupby('seller_id')['order_id']\\\n",
    "            .nunique()\\\n",
    "            .reset_index()\n",
    "        n_orders.columns = ['seller_id', 'n_orders']\n",
    "\n",
    "        quantity = order_items.groupby('seller_id', as_index=False).agg(\n",
    "            {'order_id': 'count'})\n",
    "        quantity.columns = ['seller_id', 'quantity']\n",
    "\n",
    "        result = n_orders.merge(quantity, on='seller_id')\n",
    "        result['quantity_per_order'] = result['quantity'] / result['n_orders']\n",
    "        return result\n",
    "\n",
    "    def get_sales(self):\n",
    "        \"\"\"\n",
    "        Returns a DataFrame with:\n",
    "        'seller_id', 'sales'\n",
    "        \"\"\"\n",
    "        return self.data['order_items'][['seller_id', 'price']]\\\n",
    "            .groupby('seller_id')\\\n",
    "            .sum()\\\n",
    "            .rename(columns={'price': 'sales'})\n",
    "\n",
    "    def get_review_score(self):\n",
    "        \"\"\"\n",
    "        Returns a DataFrame with:\n",
    "        'seller_id', 'share_of_five_stars', 'share_of_one_stars', 'review_score'\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î One last thing remains to be computed for each seller:\n",
    "* the proportion of extremely high reviews (`share_of_five_stars`) and the proportion of extremely poor reviews (`share_of_one_stars`)\n",
    "* the (average) `review_score`\n",
    "\n",
    "üò± Each low-rated order will indeed have a negative impact on Olist's reputation and this is modeled by the `cost_of_review`.  \n",
    "\n",
    "This will help us compute the total `cost_of_review` per seller later on!\n",
    "\n",
    "‚ùì **Implement the last method that has been left for you `get_review_score()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (4086461225.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [7], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    orders_sellers = self.data['order_items'][['order_id', 'seller_id']].drop_duplicates()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " orders_reviews = self.order.get_review_score()\n",
    "        orders_sellers = self.data['order_items'][['order_id', 'seller_id']].drop_duplicates()\n",
    "\n",
    "        df = orders_sellers.merge(orders_reviews, on='order_id')\n",
    "        res = df.groupby('seller_id', as_index=False).agg({\n",
    "            'dim_is_one_star':\n",
    "            'mean',\n",
    "            'dim_is_five_star':\n",
    "            'mean',\n",
    "            'review_score':\n",
    "            'mean'\n",
    "        })\n",
    "        # Rename columns\n",
    "        res.columns = [\n",
    "            'seller_id', 'share_of_one_stars', 'share_of_five_stars',\n",
    "            'review_score'\n",
    "        ]\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ Test your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Seller' object has no attribute 'get_training_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnbresult\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChallengeResult\n\u001b[0;32m----> 3\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mSeller\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_training_data\u001b[49m()\n\u001b[1;32m      4\u001b[0m result \u001b[38;5;241m=\u001b[39m ChallengeResult(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseller\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     shape \u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m      6\u001b[0m     median \u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m.\u001b[39mreview_score\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m result\u001b[38;5;241m.\u001b[39mwrite()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Seller' object has no attribute 'get_training_data'"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "tmp = Seller().get_training_data()\n",
    "result = ChallengeResult('seller',\n",
    "    shape = tmp.shape,\n",
    "    median = tmp.review_score.median()\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Sellers' Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Let's start with some initial ***`EDA - Exploratory Data Analysis`*** about these sellers.\n",
    "\n",
    "- üìà Plot the distribution of each numerical variable of the dataset in one large figure\n",
    "- üëÄ Do you notice any outliers?\n",
    "- What's the median of orders per seller ‚ùì\n",
    "- How does the distribution of this variable look like ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí°There seems to be a group of sellers which stands out for having very low review scores! \n",
    "\n",
    "üìä Let's investigate graphically it:\n",
    "* Using `plotly`, create a `scatterplot` of `delay_to_carrier` against `wait_time`, varying bubble size by total `sales` for that seller, and coloring by `review_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to change values `x`, `y`, `color` and `size` to try identify who are the worst sellers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Model out `review_score` with OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Scatter plots have their limits. \n",
    "\n",
    "üí° A more rigorous way to explain **`sellers' review_score`** is to **model the impact of various features on `review_score` with a `multivariate-OLS` in `statsmodels`**.\n",
    "\n",
    "üëâ Create an OLS with numerical features of your choice. \n",
    "\n",
    "‚ùì What are the most impactful ones? \n",
    "\n",
    "‚ö†Ô∏è Don't forget to standardize your features using the `standardize`function below to compare the regression coefficients together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(df, features):\n",
    "    df_standardized = df.copy()\n",
    "    for f in features:\n",
    "        mu = df[f].mean()\n",
    "        sigma = df[f].std()\n",
    "        df_standardized[f] = df[f].map(lambda x: (x - mu) / sigma)\n",
    "    return df_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìä Draw a `bar_plot` with sorted coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Finally, investigate your model's performance (`R-squared`) and `residuals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Compare the real review scores and the predicted scores by showing them on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Plot the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) Add the `seller_state` to your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì We haven't used information about `seller_state` yet.  \n",
    "- Create a new OLS model regressing `review_score` on only on `seller_states` .\n",
    "- Analyse your significant features using `return_significative_coef(model)` coded for you in `olist/utils.py`\n",
    "- What are the best states in terms of `review_score`? \n",
    "\n",
    "<details>\n",
    "    <summary>- Hints -</summary>\n",
    "        \n",
    "‚ö†Ô∏è Be careful, `seller_state` is a categorical feature. \n",
    "    \n",
    "üí° Use `C(a_cat_feature)` in the formula to tell the linear regression model which variables are categorical variables. It will create one boolean variable `is_cat_feature_xx` **per unique category** \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Some states indeed have _significantly_ better reviews than others on average. \n",
    "\n",
    "ü§î Is it due to some lower `quantity_per_order`, lower `wait_time`, or `delay_to_carrier`?  Or is it due to some other factors that we haven't collected data about?\n",
    "\n",
    "‚ùì **Try to isolate the impact of the `seller_state` from the rest by adding other continuous features to your OLS until `seller_states` is no longer statistically siginificant!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è After adding `wait_time` to our analysis, none of the 22 dummy variables `is_seller_state_xx` are statistically signigicant:\n",
    "\n",
    "Given our small dataset (most states have a very limited number of sellers):\n",
    "- We _cannot conclude_ that \"some states are inherently better than other for reasons that would be independent of the `wait_time`\" \n",
    "- In other words, we _cannot reject the hypothesis_ that \"seller_state has no impact on review_score, other than through `wait_time`\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations!\n",
    "\n",
    "üíæ Commit and push :\n",
    "* your ` sellers.ipynb`notebook \n",
    "* as well as `seller.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
